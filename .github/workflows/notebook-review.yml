# Copyright 2021 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: Execute notebooks found in a pull request and create links to their output files

on:
  pull_request:
    branches:
    - main

permissions: 
  pull-requests: 'write'
  issues: 'write'
  contents: write
  id-token: 'write'

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT }}
  REGION: us-central1	                                         # TODO: update to correct Vertex AI region
  GCS_SOURCE: ${{ secrets.GCP_PROJECT }}/ghnbr/source          # TODO: Update to a bucket with proper ACLs
  GCS_OUTPUT: ${{ secrets.GCP_PROJECT }}/ghnbr/output          # TODO: Update to a bucket with proper ACLs 
  VERTEX_MACHINE_TYPE: n1-standard-4                           # TODO: Update this to a larger VM if necessary
  VERTEX_CONTAINER: gcr.io/deeplearning-platform-release/base-cu110:latest
  VERTEX_JOB_URI: https://console.cloud.google.com/vertex-ai/locations
  VERTEX_NOTEBOOK_URI: https://notebooks.cloud.google.com/view

jobs:

  # JOB to run change detection
  changes:
    runs-on: ubuntu-latest
    # Set job outputs to values from filter step
    outputs:
      notebooks: ${{ steps.filter.outputs.notebooks }}
      notebooks_files: ${{ steps.filter.outputs.notebooks_files }}
    steps:
    # For pull requests it's not necessary to checkout the code
    - uses: dorny/paths-filter@v2
      id: filter
      with:
        list-files: shell
        filters: |
          notebooks:
            - 'somedir/**'

  # JOB to initiate the notebook review process
  notebook-review:
    name: Notebook Review
    needs: changes
    if: ${{ needs.changes.outputs.notebooks == 'true' }}
    runs-on: ubuntu-latest

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    # Look for any notebook files and copy them to a local folder
    - id: stage-files
      env: 
        files: '${{ needs.changes.outputs.notebooks_files }}'
        dir: './${{ github.sha }}'
      run: |-
        mkdir -p ${dir};
        for file in ${files}; do f2=$(echo ${file}|tr '/' '_'); cp ${file} ${dir}/${f2}; done;
        echo "::set-output name=notebooks::$(ls ${dir} | xargs)"

    # Configure Workload Identity Federation and generate an access token.
    # - id: 'auth'
    #   name: 'Authenticate to Google Cloud'
    #   uses: 'google-github-actions/auth@v0'
    #   with:
    #     workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'
    #     service_account: 'my-service-account@my-project.iam.gserviceaccount.com'

    # Alternative option - authentication via credentials json
    - id: 'auth'
      uses: 'google-github-actions/auth@v0'
      with:
        credentials_json: '${{ secrets.GOOGLE_CREDENTIALS }}'

    # Setup gcloud CLI
    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v0

    - id: 'upload-folder'
      uses: 'google-github-actions/upload-cloud-storage@v0'
      with:
        path: './${{ github.sha }}'
        destination: '${{ env.GCS_SOURCE }}'
        gzip: false
        headers: |-
          content-type: application/octet-stream

    # Submit each notebook to Vertex AI to run
    - id: 'vertex-execution'
      env:
        #notebooks: '${{ steps.stage-files.outputs.notebooks }}'
        notebooks: '${{ needs.changes.outputs.notebooks_files }}'
        commit_sha: '${{ github.sha }}'
        output_location: 'gs://${{ env.GCS_OUTPUT }}'
        source_location: 'gs://${{ env.GCS_SOURCE }}'
      run: |-
        training_jobs='{"jobs": [';

        for file in ${notebooks};
        do
          file=$(echo ${file}|tr '/' '_');
          echo ${file}
          job_name="${commit_sha}:${file}";
          source_file="${source_location}/${commit_sha}/${file}";
          output_file="${output_location}/${commit_sha}/${file}";

          echo gcloud ai custom-jobs create \
             --region=${REGION} \
             --display-name="${job_name}" \
             --labels=commit_sha=${commit_sha} \
             --worker-pool-spec=machine-type="${VERTEX_MACHINE_TYPE}",replica-count="1",container-image-uri="${VERTEX_CONTAINER}" \
             --args=nbexecutor,--input-notebook="${source_file}",--output-notebook="${output_file}",--kernel-name=python3;

          output=$(gcloud ai custom-jobs create \
             --format=json \
             --region=${REGION} \
             --display-name="${job_name}" \
             --labels=commit_sha=${commit_sha} \
             --worker-pool-spec=machine-type="${VERTEX_MACHINE_TYPE}",replica-count="1",container-image-uri="${VERTEX_CONTAINER}" \
             --args=nbexecutor,--input-notebook="${source_file}",--output-notebook="${output_file}",--kernel-name=python3);

          training_jobs="${training_jobs}${output},";

        done;

        training_jobs="${training_jobs}]}";

        echo "${training_jobs}" | tr -d '\r' | tr -d '\n' | sed 's/,]/]/g' > training.json;
        echo "::set-output name=training_jobs::$(cat training.json)";

    - id: 'update-pr'
      env: 
        training_jobs: '${{ steps.vertex-execution.outputs.training_jobs }}'
      uses: actions/github-script@v6
      with:
        script: |
          const region = process.env.REGION;
          const notebookUri = process.env.VERTEX_NOTEBOOK_URI;
          const vertexUri = process.env.VERTEX_JOB_URI;
          const jsonStr = process.env.training_jobs;
          const project = process.env.PROJECT_ID;

          const data = JSON.parse(jsonStr);
          const jid_re = /\/([0-9]+)$/;
          for (const ix in data.jobs) {
            const job = data.jobs[ix];
            const nbName = job.displayName.split(":")[1];
            const jobId = job.name.match(jid_re)[0].replace("/", "");
            const outFile = job.jobSpec.workerPoolSpecs[0].containerSpec.args.filter((a) => a.startsWith("--output-notebook=gs://")).map((a) => a.replace("--output-notebook=gs://", ""))[0];
            const message = `Automatic running of notebook **${nbName}** underway.

            You can review the status of the job within Vertex AI: [Job ${jobId}](${vertexUri}/${region}/training/${jobId}?project=${project})

            Once complete the notebook with output cells will be available to view [${nbName}](${notebookUri}/${outFile})`;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: message,
            });
          }


